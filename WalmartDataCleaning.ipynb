{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXM32f51xtBR"
   },
   "source": [
    "# Walmart Products Dataset Preprocessing\n",
    "\n",
    "This script performs preliminary cleaning of the Walmart Products dataset from Kaggle, which can be found [here](https://www.kaggle.com/datasets/thedevastator/product-prices-and-sizes-from-walmart-grocery/code).\n",
    "\n",
    "Some of the cleaning steps were inspired by a similar project on Walmart price prediction on Kaggle, which can be found [here](https://www.kaggle.com/code/ryanbell62101/walmart-product-price-predictor).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nOBR7MmGS8MC"
   },
   "outputs": [],
   "source": [
    "# Necessary Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHt87WkU5tfx"
   },
   "source": [
    "## Step 1: Read in Dataset\n",
    "\n",
    "First, we want to a look at the dataset and verify that it imported successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "id": "WuO2nZvGUknw",
    "outputId": "1b3b9137-0de3-44aa-8cdc-79bc5fe1780c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7p/xb2glmy50v59_g4kfskbtjz80000gn/T/ipykernel_13353/345100623.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  walmart = pd.read_csv('walmart_dataset.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>SHIPPING_LOCATION</th>\n",
       "      <th>DEPARTMENT</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>SUBCATEGORY</th>\n",
       "      <th>BREADCRUMBS</th>\n",
       "      <th>SKU</th>\n",
       "      <th>PRODUCT_URL</th>\n",
       "      <th>PRODUCT_NAME</th>\n",
       "      <th>BRAND</th>\n",
       "      <th>PRICE_RETAIL</th>\n",
       "      <th>PRICE_CURRENT</th>\n",
       "      <th>PRODUCT_SIZE</th>\n",
       "      <th>PROMOTION</th>\n",
       "      <th>RunDate</th>\n",
       "      <th>tid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>79936</td>\n",
       "      <td>Deli</td>\n",
       "      <td>Hummus, Dips, &amp; Salsa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Deli/Hummus, Dips, &amp; Salsa</td>\n",
       "      <td>110895339</td>\n",
       "      <td>https://www.walmart.com/ip/Marketside-Roasted-...</td>\n",
       "      <td>Marketside Roasted Red Pepper Hummus, 10 Oz</td>\n",
       "      <td>Marketside</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2.67</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-09-11 21:20:04</td>\n",
       "      <td>16163804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>79936</td>\n",
       "      <td>Deli</td>\n",
       "      <td>Hummus, Dips, &amp; Salsa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Deli/Hummus, Dips, &amp; Salsa</td>\n",
       "      <td>105455228</td>\n",
       "      <td>https://www.walmart.com/ip/Marketside-Roasted-...</td>\n",
       "      <td>Marketside Roasted Garlic Hummus, 10 Oz</td>\n",
       "      <td>Marketside</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2.67</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-09-11 21:20:04</td>\n",
       "      <td>16163805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>79936</td>\n",
       "      <td>Deli</td>\n",
       "      <td>Hummus, Dips, &amp; Salsa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Deli/Hummus, Dips, &amp; Salsa</td>\n",
       "      <td>128642379</td>\n",
       "      <td>https://www.walmart.com/ip/Marketside-Classic-...</td>\n",
       "      <td>Marketside Classic Hummus, 10 Oz</td>\n",
       "      <td>Marketside</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2.67</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-09-11 21:20:04</td>\n",
       "      <td>16163806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>79936</td>\n",
       "      <td>Deli</td>\n",
       "      <td>Hummus, Dips, &amp; Salsa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Deli/Hummus, Dips, &amp; Salsa</td>\n",
       "      <td>366126367</td>\n",
       "      <td>https://www.walmart.com/ip/Marketside-Everythi...</td>\n",
       "      <td>Marketside Everything Hummus, 10 oz</td>\n",
       "      <td>Marketside</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2.67</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-09-11 21:20:04</td>\n",
       "      <td>16163807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>79936</td>\n",
       "      <td>Deli</td>\n",
       "      <td>Hummus, Dips, &amp; Salsa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Deli/Hummus, Dips, &amp; Salsa</td>\n",
       "      <td>160090316</td>\n",
       "      <td>https://www.walmart.com/ip/Price-s-Jalapeno-Di...</td>\n",
       "      <td>Price's Jalapeno Dip, 12 Oz.</td>\n",
       "      <td>Price's</td>\n",
       "      <td>3.12</td>\n",
       "      <td>3.12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-09-11 21:20:04</td>\n",
       "      <td>16163808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  SHIPPING_LOCATION DEPARTMENT               CATEGORY SUBCATEGORY  \\\n",
       "0      0              79936       Deli  Hummus, Dips, & Salsa         NaN   \n",
       "1      1              79936       Deli  Hummus, Dips, & Salsa         NaN   \n",
       "2      2              79936       Deli  Hummus, Dips, & Salsa         NaN   \n",
       "3      3              79936       Deli  Hummus, Dips, & Salsa         NaN   \n",
       "4      4              79936       Deli  Hummus, Dips, & Salsa         NaN   \n",
       "\n",
       "                  BREADCRUMBS        SKU  \\\n",
       "0  Deli/Hummus, Dips, & Salsa  110895339   \n",
       "1  Deli/Hummus, Dips, & Salsa  105455228   \n",
       "2  Deli/Hummus, Dips, & Salsa  128642379   \n",
       "3  Deli/Hummus, Dips, & Salsa  366126367   \n",
       "4  Deli/Hummus, Dips, & Salsa  160090316   \n",
       "\n",
       "                                         PRODUCT_URL  \\\n",
       "0  https://www.walmart.com/ip/Marketside-Roasted-...   \n",
       "1  https://www.walmart.com/ip/Marketside-Roasted-...   \n",
       "2  https://www.walmart.com/ip/Marketside-Classic-...   \n",
       "3  https://www.walmart.com/ip/Marketside-Everythi...   \n",
       "4  https://www.walmart.com/ip/Price-s-Jalapeno-Di...   \n",
       "\n",
       "                                  PRODUCT_NAME       BRAND  PRICE_RETAIL  \\\n",
       "0  Marketside Roasted Red Pepper Hummus, 10 Oz  Marketside          2.67   \n",
       "1      Marketside Roasted Garlic Hummus, 10 Oz  Marketside          2.67   \n",
       "2             Marketside Classic Hummus, 10 Oz  Marketside          2.67   \n",
       "3          Marketside Everything Hummus, 10 oz  Marketside          2.67   \n",
       "4                 Price's Jalapeno Dip, 12 Oz.     Price's          3.12   \n",
       "\n",
       "   PRICE_CURRENT PRODUCT_SIZE  PROMOTION              RunDate       tid  \n",
       "0           2.67           10        NaN  2022-09-11 21:20:04  16163804  \n",
       "1           2.67           10        NaN  2022-09-11 21:20:04  16163805  \n",
       "2           2.67           10        NaN  2022-09-11 21:20:04  16163806  \n",
       "3           2.67           10        NaN  2022-09-11 21:20:04  16163807  \n",
       "4           3.12           12        NaN  2022-09-11 21:20:04  16163808  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in dataset and display the top couple of rows to verify it imported properly\n",
    "walmart = pd.read_csv('walmart_dataset.csv')\n",
    "walmart.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iPlR4krk5rPS"
   },
   "source": [
    "## Step 2: Look for Unique Values in each Feature\n",
    "\n",
    "Each feature that provides meaningful information should have a decent amount of unique values across a dataset with 569k entries. Therefore, we want to remove any features that have low numbers of unique values, as low uniqueness indicates there is not much variation in that feature across the data entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 586
    },
    "id": "ENy3xtMmrTJA",
    "outputId": "4ea22a63-8fe6-47c4-e4fc-31a320b38daf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                568534\n",
       "SHIPPING_LOCATION        26\n",
       "DEPARTMENT               14\n",
       "CATEGORY                114\n",
       "SUBCATEGORY             125\n",
       "BREADCRUMBS             116\n",
       "SKU                   30827\n",
       "PRODUCT_URL           32008\n",
       "PRODUCT_NAME          30688\n",
       "BRAND                  4368\n",
       "PRICE_RETAIL           1852\n",
       "PRICE_CURRENT          1833\n",
       "PRODUCT_SIZE           1290\n",
       "PROMOTION                 0\n",
       "RunDate                   1\n",
       "tid                  568534\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyze number of unique items in each column\n",
    "unique = walmart.nunique()\n",
    "unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "vAe9MRx6roWn"
   },
   "outputs": [],
   "source": [
    "# Drop \"Promotion\" and \"RunDate\" features as they only have 0 and 1 unique values respectively, so they provide no valuable info\n",
    "walmart.drop(columns=['RunDate', 'PROMOTION'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCD3On706a67"
   },
   "source": [
    "## Step 3: Deal with Missing Data\n",
    "\n",
    "Next, we want to analyze how much missing data (typically \"NA\" values) are in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "id": "1tTkjKeD2lOS",
    "outputId": "8799bc71-c949-4084-fb13-710dde0cb996"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                     0\n",
       "SHIPPING_LOCATION         0\n",
       "DEPARTMENT                0\n",
       "CATEGORY                  0\n",
       "SUBCATEGORY          207210\n",
       "BREADCRUMBS               0\n",
       "SKU                       0\n",
       "PRODUCT_URL               0\n",
       "PRODUCT_NAME              0\n",
       "BRAND                    27\n",
       "PRICE_RETAIL              0\n",
       "PRICE_CURRENT             0\n",
       "PRODUCT_SIZE          62825\n",
       "tid                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum all missing values for each feature\n",
    "walmart.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alRapNr26l_Q"
   },
   "source": [
    "Here, we see that Brand and Product Size have a relatively minor amount of NA values, in comparison to Subcategory which has 207k NA values. Therefore, we want to initially keep the entries with NA values for Subcategory to avoid removing too much data. In the meantime, we choose to get rid of the entries with NA for Brand and Product Size for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 668
    },
    "id": "05BvE-EmsNz_",
    "outputId": "d79763b2-b48d-4ccb-daf6-e3990abc867f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7p/xb2glmy50v59_g4kfskbtjz80000gn/T/ipykernel_13353/2297702649.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  walmart['SUBCATEGORY'].fillna('none', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "index                0\n",
       "SHIPPING_LOCATION    0\n",
       "DEPARTMENT           0\n",
       "CATEGORY             0\n",
       "SUBCATEGORY          0\n",
       "BREADCRUMBS          0\n",
       "SKU                  0\n",
       "PRODUCT_URL          0\n",
       "PRODUCT_NAME         0\n",
       "BRAND                0\n",
       "PRICE_RETAIL         0\n",
       "PRICE_CURRENT        0\n",
       "PRODUCT_SIZE         0\n",
       "tid                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subcategory has too many missing values to remove all associated data, otherwise dataset would significantly shrink\n",
    "walmart['SUBCATEGORY'].fillna('none', inplace=True)\n",
    "\n",
    "walmart.dropna(inplace=True) # Drop entries with NA values for product_name and product_size\n",
    "walmart.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JaQU75P7Dv_"
   },
   "source": [
    "### Step 3: Analyze Data Types for Each Feature\n",
    "\n",
    "Now, we should verify the data types for each feature to ensure that each data type makes logical sense and will be what we want to use moving forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "epZionwm48Wv",
    "outputId": "9b5ec9aa-a36f-4d0a-cf73-66128c4eb2a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 505709 entries, 0 to 568533\n",
      "Data columns (total 14 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   index              505709 non-null  int64  \n",
      " 1   SHIPPING_LOCATION  505709 non-null  int64  \n",
      " 2   DEPARTMENT         505709 non-null  object \n",
      " 3   CATEGORY           505709 non-null  object \n",
      " 4   SUBCATEGORY        505709 non-null  object \n",
      " 5   BREADCRUMBS        505709 non-null  object \n",
      " 6   SKU                505709 non-null  int64  \n",
      " 7   PRODUCT_URL        505709 non-null  object \n",
      " 8   PRODUCT_NAME       505709 non-null  object \n",
      " 9   BRAND              505709 non-null  object \n",
      " 10  PRICE_RETAIL       505709 non-null  float64\n",
      " 11  PRICE_CURRENT      505709 non-null  float64\n",
      " 12  PRODUCT_SIZE       505709 non-null  object \n",
      " 13  tid                505709 non-null  int64  \n",
      "dtypes: float64(2), int64(4), object(8)\n",
      "memory usage: 57.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Look at overview of dataset thus far\n",
    "walmart.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LnpmN9Co7SpZ"
   },
   "source": [
    "Here, we notice that product size is an \"object\" instead of a number. This should be a numerical value instead of a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "kPzC54qvuYaC"
   },
   "outputs": [],
   "source": [
    "# Product size should be numerical, take digits out of string and convert into numerical format\n",
    "def get_digits(string):\n",
    "    digit_search = re.search('([0-9]+)', string)\n",
    "    return digit_search.group(1) if digit_search else None\n",
    "\n",
    "walmart['PRODUCT_SIZE'] = pd.to_numeric(walmart['PRODUCT_SIZE'].map(get_digits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q120PltO72yN"
   },
   "source": [
    "Another issue is that, for entries with strings such as Product Category, Product Subcategory, Brand, and Breadcrumbs, we should standardize letter casing in order to remove duplicate entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "id": "DwKG6hRSwPOj",
    "outputId": "fb11b0d7-36ea-4077-85eb-da3da9f61c37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                505709\n",
       "SHIPPING_LOCATION        26\n",
       "DEPARTMENT               14\n",
       "CATEGORY                113\n",
       "SUBCATEGORY             121\n",
       "BREADCRUMBS             115\n",
       "SKU                   26604\n",
       "PRODUCT_URL           27634\n",
       "PRODUCT_NAME          26537\n",
       "BRAND                  3871\n",
       "PRICE_RETAIL           1709\n",
       "PRICE_CURRENT          1684\n",
       "PRODUCT_SIZE            137\n",
       "tid                  505709\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminate duplicate entries by converting all text to lowercase\n",
    "walmart['CATEGORY'] = walmart['CATEGORY'].str.lower()\n",
    "walmart['SUBCATEGORY'] = walmart['SUBCATEGORY'].str.lower()\n",
    "walmart['BRAND'] = walmart['BRAND'].str.lower()\n",
    "walmart['BREADCRUMBS'] = walmart['BREADCRUMBS'].str.lower()\n",
    "\n",
    "walmart.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uC4AHx758W0O"
   },
   "source": [
    "## Step 4: Final Clean and Organization of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "id": "nwjQ8K4mwegx",
    "outputId": "2c527ab5-abb8-438a-d1f6-35f5d892a073"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                  0\n",
       "SHIPPING_LOCATION      0\n",
       "DEPARTMENT             0\n",
       "CATEGORY               0\n",
       "SUBCATEGORY            0\n",
       "BREADCRUMBS            0\n",
       "SKU                    0\n",
       "PRODUCT_URL            0\n",
       "PRODUCT_NAME           0\n",
       "BRAND                  0\n",
       "PRICE_RETAIL           0\n",
       "PRICE_CURRENT          0\n",
       "PRODUCT_SIZE         202\n",
       "tid                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if any new NA values were introduced in the above steps\n",
    "walmart.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "id": "vw34zEIUwrwW",
    "outputId": "431a9f94-9a56-4384-8f00-4be7108a9d5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                0\n",
       "SHIPPING_LOCATION    0\n",
       "DEPARTMENT           0\n",
       "CATEGORY             0\n",
       "SUBCATEGORY          0\n",
       "BREADCRUMBS          0\n",
       "SKU                  0\n",
       "PRODUCT_URL          0\n",
       "PRODUCT_NAME         0\n",
       "BRAND                0\n",
       "PRICE_RETAIL         0\n",
       "PRICE_CURRENT        0\n",
       "PRODUCT_SIZE         0\n",
       "tid                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop any new NA values and re-verify\n",
    "walmart.dropna(inplace=True)\n",
    "walmart.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "id": "Xns2vUvOw4JD",
    "outputId": "2d8abeba-e4da-4665-c044-8c566c8635c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">PRICE_RETAIL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>SUBCATEGORY</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bacon, hot dogs, sausage</th>\n",
       "      <th>none</th>\n",
       "      <td>5939.0</td>\n",
       "      <td>5.474102</td>\n",
       "      <td>3.054611</td>\n",
       "      <td>0.84</td>\n",
       "      <td>3.78</td>\n",
       "      <td>4.72</td>\n",
       "      <td>6.84</td>\n",
       "      <td>24.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baking nuts &amp; seeds</th>\n",
       "      <th>none</th>\n",
       "      <td>552.0</td>\n",
       "      <td>6.776793</td>\n",
       "      <td>4.086878</td>\n",
       "      <td>1.18</td>\n",
       "      <td>3.24</td>\n",
       "      <td>6.12</td>\n",
       "      <td>9.30</td>\n",
       "      <td>17.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baking soda &amp; starch</th>\n",
       "      <th>none</th>\n",
       "      <td>434.0</td>\n",
       "      <td>3.898710</td>\n",
       "      <td>3.824149</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.48</td>\n",
       "      <td>2.48</td>\n",
       "      <td>4.12</td>\n",
       "      <td>15.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beef jerky</th>\n",
       "      <th>none</th>\n",
       "      <td>1510.0</td>\n",
       "      <td>8.375377</td>\n",
       "      <td>3.907909</td>\n",
       "      <td>1.08</td>\n",
       "      <td>4.98</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.98</td>\n",
       "      <td>18.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beer</th>\n",
       "      <th>domestic beer</th>\n",
       "      <td>1490.0</td>\n",
       "      <td>12.444389</td>\n",
       "      <td>5.758637</td>\n",
       "      <td>1.48</td>\n",
       "      <td>7.99</td>\n",
       "      <td>12.98</td>\n",
       "      <td>16.98</td>\n",
       "      <td>27.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">wine</th>\n",
       "      <th>sparkling wine</th>\n",
       "      <td>739.0</td>\n",
       "      <td>13.576685</td>\n",
       "      <td>8.817995</td>\n",
       "      <td>3.72</td>\n",
       "      <td>8.98</td>\n",
       "      <td>11.48</td>\n",
       "      <td>14.98</td>\n",
       "      <td>67.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>specialty wine</th>\n",
       "      <td>48.0</td>\n",
       "      <td>9.535417</td>\n",
       "      <td>3.102972</td>\n",
       "      <td>5.48</td>\n",
       "      <td>6.98</td>\n",
       "      <td>8.98</td>\n",
       "      <td>11.48</td>\n",
       "      <td>18.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white wine</th>\n",
       "      <td>2190.0</td>\n",
       "      <td>10.602868</td>\n",
       "      <td>4.910865</td>\n",
       "      <td>2.96</td>\n",
       "      <td>6.99</td>\n",
       "      <td>9.98</td>\n",
       "      <td>12.98</td>\n",
       "      <td>90.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yeast</th>\n",
       "      <th>none</th>\n",
       "      <td>237.0</td>\n",
       "      <td>3.521561</td>\n",
       "      <td>1.981249</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.72</td>\n",
       "      <td>4.62</td>\n",
       "      <td>5.18</td>\n",
       "      <td>6.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yogurt</th>\n",
       "      <th>none</th>\n",
       "      <td>6773.0</td>\n",
       "      <td>2.897639</td>\n",
       "      <td>2.017740</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.22</td>\n",
       "      <td>2.18</td>\n",
       "      <td>4.37</td>\n",
       "      <td>15.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        PRICE_RETAIL                       \\\n",
       "                                               count       mean       std   \n",
       "CATEGORY                 SUBCATEGORY                                        \n",
       "bacon, hot dogs, sausage none                 5939.0   5.474102  3.054611   \n",
       "baking nuts & seeds      none                  552.0   6.776793  4.086878   \n",
       "baking soda & starch     none                  434.0   3.898710  3.824149   \n",
       "beef jerky               none                 1510.0   8.375377  3.907909   \n",
       "beer                     domestic beer        1490.0  12.444389  5.758637   \n",
       "...                                              ...        ...       ...   \n",
       "wine                     sparkling wine        739.0  13.576685  8.817995   \n",
       "                         specialty wine         48.0   9.535417  3.102972   \n",
       "                         white wine           2190.0  10.602868  4.910865   \n",
       "yeast                    none                  237.0   3.521561  1.981249   \n",
       "yogurt                   none                 6773.0   2.897639  2.017740   \n",
       "\n",
       "                                                                          \n",
       "                                          min   25%    50%    75%    max  \n",
       "CATEGORY                 SUBCATEGORY                                      \n",
       "bacon, hot dogs, sausage none            0.84  3.78   4.72   6.84  24.66  \n",
       "baking nuts & seeds      none            1.18  3.24   6.12   9.30  17.92  \n",
       "baking soda & starch     none            0.72  1.48   2.48   4.12  15.86  \n",
       "beef jerky               none            1.08  4.98   7.88  11.98  18.58  \n",
       "beer                     domestic beer   1.48  7.99  12.98  16.98  27.98  \n",
       "...                                       ...   ...    ...    ...    ...  \n",
       "wine                     sparkling wine  3.72  8.98  11.48  14.98  67.27  \n",
       "                         specialty wine  5.48  6.98   8.98  11.48  18.98  \n",
       "                         white wine      2.96  6.99   9.98  12.98  90.00  \n",
       "yeast                    none            0.86  1.72   4.62   5.18   6.37  \n",
       "yogurt                   none            0.52  1.22   2.18   4.37  15.18  \n",
       "\n",
       "[208 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the data in a hierarchical structure by categories followed by subcategories\n",
    "category_groups = walmart.groupby(['CATEGORY','SUBCATEGORY'])\n",
    "category_groups[['PRICE_RETAIL']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned dataset\n",
    "walmart.to_csv(\"walmart_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: walmart_cleaned.csv...\n",
      "\n",
      "--- Details for column 'SHIPPING_LOCATION' ---\n",
      "\n",
      "1. Missing values (NA) count: 0\n",
      "\n",
      "2. Number of unique store IDs: 26\n",
      "\n",
      "3. List of unique store IDs:\n",
      "[79936 48180 96797 94565 23223 75211 89108 15601 23111 33012 72034 60007\n",
      " 63376 44035 53215 33647  6010 66062 90650 78130 85225 75052 70072 77449\n",
      " 30044 45011]\n",
      "\n",
      "4. Value counts per ID:\n",
      "SHIPPING_LOCATION\n",
      "33647    23526\n",
      "23223    23085\n",
      "44035    23067\n",
      "77449    22370\n",
      "75052    22367\n",
      "48180    22254\n",
      "15601    22233\n",
      "53215    22150\n",
      "70072    21964\n",
      "23111    21885\n",
      "60007    21833\n",
      "45011    21802\n",
      "75211    21622\n",
      "78130    21412\n",
      "85225    20144\n",
      "30044    19887\n",
      "90650    19469\n",
      "66062    19161\n",
      "63376    19141\n",
      "72034    18176\n",
      "89108    17887\n",
      "79936    17555\n",
      "33012    15371\n",
      "96797     9917\n",
      "94565     8783\n",
      "6010      8446\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Details for column 'SHIPPING_LOCATION' ---\n",
      "\n",
      "1. Missing values (NA) count: 0\n",
      "\n",
      "2. Number of unique store IDs: 26\n",
      "\n",
      "3. List of unique store IDs:\n",
      "[79936 48180 96797 94565 23223 75211 89108 15601 23111 33012 72034 60007\n",
      " 63376 44035 53215 33647  6010 66062 90650 78130 85225 75052 70072 77449\n",
      " 30044 45011]\n",
      "\n",
      "4. Value counts per ID:\n",
      "SHIPPING_LOCATION\n",
      "33647    23526\n",
      "23223    23085\n",
      "44035    23067\n",
      "77449    22370\n",
      "75052    22367\n",
      "48180    22254\n",
      "15601    22233\n",
      "53215    22150\n",
      "70072    21964\n",
      "23111    21885\n",
      "60007    21833\n",
      "45011    21802\n",
      "75211    21622\n",
      "78130    21412\n",
      "85225    20144\n",
      "30044    19887\n",
      "90650    19469\n",
      "66062    19161\n",
      "63376    19141\n",
      "72034    18176\n",
      "89108    17887\n",
      "79936    17555\n",
      "33012    15371\n",
      "96797     9917\n",
      "94565     8783\n",
      "6010      8446\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filename = \"walmart_cleaned.csv\"\n",
    "column_to_check = \"SHIPPING_LOCATION\"\n",
    "\n",
    "print(f\"Loading file: {filename}...\")\n",
    "df = pd.read_csv(filename, usecols=[column_to_check])\n",
    "\n",
    "print(f\"\\n--- Details for column '{column_to_check}' ---\")\n",
    "\n",
    "missing_values = df[column_to_check].isna().sum()\n",
    "print(f\"\\n1. Missing values (NA) count: {missing_values}\")\n",
    "\n",
    "unique_count = df[column_to_check].nunique()\n",
    "print(f\"\\n2. Number of unique store IDs: {unique_count}\")\n",
    "\n",
    "unique_ids = df[column_to_check].unique()\n",
    "print(\"\\n3. List of unique store IDs:\")\n",
    "print(unique_ids)\n",
    "\n",
    "print(\"\\n4. Value counts per ID:\")\n",
    "print(df[column_to_check].value_counts())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cleaned Walmart data: walmart_cleaned.csv...\n",
      "Loading ZIP database: uszips.csv...\n",
      "Merging coordinates into Walmart data...\n",
      "\n",
      "--- Merge complete! ---\n",
      "Preview of merged data (includes coordinates):\n",
      "Loading ZIP database: uszips.csv...\n",
      "Merging coordinates into Walmart data...\n",
      "\n",
      "--- Merge complete! ---\n",
      "Preview of merged data (includes coordinates):\n",
      "                                  PRODUCT_NAME SHIPPING_LOCATION  latitude  \\\n",
      "0  Marketside Roasted Red Pepper Hummus, 10 Oz             79936  31.77373   \n",
      "1      Marketside Roasted Garlic Hummus, 10 Oz             79936  31.77373   \n",
      "2             Marketside Classic Hummus, 10 Oz             79936  31.77373   \n",
      "3          Marketside Everything Hummus, 10 oz             79936  31.77373   \n",
      "4                 Price's Jalapeno Dip, 12 Oz.             79936  31.77373   \n",
      "\n",
      "   longitude     city  \n",
      "0 -106.29631  El Paso  \n",
      "1 -106.29631  El Paso  \n",
      "2 -106.29631  El Paso  \n",
      "3 -106.29631  El Paso  \n",
      "4 -106.29631  El Paso  \n",
      "\n",
      "Warning: 8446 rows did not match a coordinate.\n",
      "                                  PRODUCT_NAME SHIPPING_LOCATION  latitude  \\\n",
      "0  Marketside Roasted Red Pepper Hummus, 10 Oz             79936  31.77373   \n",
      "1      Marketside Roasted Garlic Hummus, 10 Oz             79936  31.77373   \n",
      "2             Marketside Classic Hummus, 10 Oz             79936  31.77373   \n",
      "3          Marketside Everything Hummus, 10 oz             79936  31.77373   \n",
      "4                 Price's Jalapeno Dip, 12 Oz.             79936  31.77373   \n",
      "\n",
      "   longitude     city  \n",
      "0 -106.29631  El Paso  \n",
      "1 -106.29631  El Paso  \n",
      "2 -106.29631  El Paso  \n",
      "3 -106.29631  El Paso  \n",
      "4 -106.29631  El Paso  \n",
      "\n",
      "Warning: 8446 rows did not match a coordinate.\n",
      "\n",
      "Saved enriched dataset to: walmart_with_coordinates.csv\n",
      "\n",
      "Saved enriched dataset to: walmart_with_coordinates.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cleaned_walmart_file = \"walmart_cleaned.csv\"\n",
    "zip_database_file = \"uszips.csv\" \n",
    "print(f\"Loading cleaned Walmart data: {cleaned_walmart_file}...\")\n",
    "walmart_df = pd.read_csv(cleaned_walmart_file, dtype=str)\n",
    "\n",
    "print(f\"Loading ZIP database: {zip_database_file}...\")\n",
    "zip_db = pd.read_csv(zip_database_file, dtype=str)\n",
    "\n",
    "# --- Key preparation: standardize column names and types ---\n",
    "# Support common name variants: 'zip' + ('lat','lng') or 'zip_code' + ('latitude','longitude')\n",
    "if 'zip' in zip_db.columns:\n",
    "    zip_db.rename(columns={\n",
    "        'zip': 'SHIPPING_LOCATION',\n",
    "        'lat': 'latitude',\n",
    "        'lng': 'longitude'\n",
    "    }, inplace=True)\n",
    "elif 'zip_code' in zip_db.columns:\n",
    "    zip_db.rename(columns={'zip_code': 'SHIPPING_LOCATION'}, inplace=True)\n",
    "else:\n",
    "    print(\"--- Error: could not find 'zip' or 'zip_code' column in ZIP database ---\")\n",
    "    print(\"Please inspect the CSV and update the rename logic accordingly.\")\n",
    "    raise KeyError(\"Zip code column not found\")\n",
    "\n",
    "zip_db['SHIPPING_LOCATION'] = zip_db['SHIPPING_LOCATION'].astype(str).str.strip().str.zfill(5)\n",
    "\n",
    "for geo_col in ('latitude', 'longitude'):\n",
    "    if geo_col in zip_db.columns:\n",
    "        zip_db[geo_col] = pd.to_numeric(zip_db[geo_col], errors='coerce')\n",
    "\n",
    "columns_to_merge = ['SHIPPING_LOCATION', 'latitude', 'longitude', 'city', 'state_id']\n",
    "columns_to_merge = [col for col in columns_to_merge if col in zip_db.columns]\n",
    "\n",
    "print(\"Merging coordinates into Walmart data...\")\n",
    "walmart_with_coords = pd.merge(\n",
    "    walmart_df,\n",
    "    zip_db[columns_to_merge],  # only merge the columns we need\n",
    "    on=\"SHIPPING_LOCATION\",   # merge key (e.g., '00601', '30044')\n",
    "    how=\"left\"                # keep all Walmart items even if some ZIPs don't match\n",
    ")\n",
    "\n",
    "print(\"\\n--- Merge complete! ---\")\n",
    "print(\"Preview of merged data (includes coordinates):\")\n",
    "\n",
    "preview_cols = [c for c in ['PRODUCT_NAME', 'SHIPPING_LOCATION', 'latitude', 'longitude', 'city'] if c in walmart_with_coords.columns]\n",
    "print(walmart_with_coords[preview_cols].head())\n",
    "\n",
    "unmatched_rows = walmart_with_coords['latitude'].isna().sum() if 'latitude' in walmart_with_coords.columns else 0\n",
    "if unmatched_rows > 0:\n",
    "    print(f\"\\n Warning: {unmatched_rows} rows did not match a coordinate.\")\n",
    "else:\n",
    "    print(\"\\n All rows matched coordinates!\")\n",
    "\n",
    "output_file = \"walmart_with_coordinates.csv\"\n",
    "walmart_with_coords.to_csv(output_file, index=False)\n",
    "print(f\"\\nSaved enriched dataset to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnosis and imputation strategies for unmatched ZIP codes\n",
    "\n",
    "The following cell will:\n",
    "- Show the distribution of `SHIPPING_LOCATION` values that failed to merge (sorted by frequency).\n",
    "- Attempt imputation using the mean latitude/longitude for the ZIP prefix (first 3 digits).\n",
    "- If available, try imputing using state-level centroids (`state_id`).\n",
    "- Finally save the imputed dataset to `walmart_with_coordinates_imputed.csv` and report remaining unmatched counts.\n",
    "\n",
    "These methods provide reasonable approximate locations for analysis and visualization without calling external geocoding APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walmart_with_coords columns: ['index', 'SHIPPING_LOCATION', 'DEPARTMENT', 'CATEGORY', 'SUBCATEGORY', 'BREADCRUMBS', 'SKU', 'PRODUCT_URL', 'PRODUCT_NAME', 'BRAND', 'PRICE_RETAIL', 'PRICE_CURRENT', 'PRODUCT_SIZE', 'tid', 'latitude', 'longitude', 'city', 'state_id']\n",
      "Total unmatched rows: 8446\n",
      "\n",
      "Top 30 unmatched SHIPPING_LOCATION values (with counts):\n",
      "SHIPPING_LOCATION\n",
      "6010    8446\n",
      "Name: count, dtype: int64\n",
      "Number of prefixes available for prefix-based imputation: 896\n",
      "Number of states available for state-based imputation: 56\n",
      "Remaining unmatched rows after imputation: 0\n",
      "\n",
      "Imputation method counts (top examples):\n",
      "_imputed_by\n",
      "prefix:601    8446\n",
      "Name: count, dtype: int64\n",
      "Remaining unmatched rows after imputation: 0\n",
      "\n",
      "Imputation method counts (top examples):\n",
      "_imputed_by\n",
      "prefix:601    8446\n",
      "Name: count, dtype: int64\n",
      "Imputed dataset saved to: walmart_with_coordinates_imputed.csv\n",
      "Imputed dataset saved to: walmart_with_coordinates_imputed.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "print('walmart_with_coords columns:', list(walmart_with_coords.columns))\n",
    "\n",
    "# 1) Show examples and frequencies of unmatched SHIPPING_LOCATION values\n",
    "unmatched_mask = walmart_with_coords['latitude'].isna()\n",
    "unmatched = walmart_with_coords[unmatched_mask].copy()\n",
    "total_unmatched = len(unmatched)\n",
    "print(f'Total unmatched rows: {total_unmatched}')\n",
    "if total_unmatched == 0:\n",
    "    print('No unmatched rows — no imputation required.')\n",
    "else:\n",
    "    print('\\nTop 30 unmatched SHIPPING_LOCATION values (with counts):')\n",
    "    print(unmatched['SHIPPING_LOCATION'].value_counts().head(30))\n",
    "\n",
    "    # 2) Try prefix-based imputation: build mean lat/lon per 3-digit prefix\n",
    "    # Only possible if zip_db contains latitude/longitude\n",
    "    if 'latitude' in zip_db.columns and 'longitude' in zip_db.columns:\n",
    "        zip_db['prefix'] = zip_db['SHIPPING_LOCATION'].astype(str).str[:3]\n",
    "        prefix_centroid = zip_db.groupby('prefix')[['latitude','longitude']].mean().reset_index().set_index('prefix')\n",
    "        print(f'Number of prefixes available for prefix-based imputation: {len(prefix_centroid)}')\n",
    "    else:\n",
    "        prefix_centroid = None\n",
    "        print('zip database lacks latitude/longitude — prefix imputation not available.')\n",
    "\n",
    "    # 3) If state_id is present, build state-level centroids (preferable to global mean)\n",
    "    state_centroid = None\n",
    "    if 'state_id' in zip_db.columns and 'latitude' in zip_db.columns and 'longitude' in zip_db.columns:\n",
    "        state_centroid = zip_db.groupby('state_id')[['latitude','longitude']].mean().reset_index().set_index('state_id')\n",
    "        print(f'Number of states available for state-based imputation: {len(state_centroid)}')\n",
    "\n",
    "    # 4) Imputation order: prefix -> state -> global mean\n",
    "    global_mean = None\n",
    "    if 'latitude' in zip_db.columns and 'longitude' in zip_db.columns:\n",
    "        global_mean = zip_db[['latitude','longitude']].astype(float).mean().to_dict()\n",
    "\n",
    "\n",
    "    def impute_row(row):\n",
    "\n",
    "        if not pd.isna(row['latitude']):\n",
    "            return row\n",
    "        ship = str(row['SHIPPING_LOCATION']) if pd.notna(row['SHIPPING_LOCATION']) else ''\n",
    "        prefix = ship[:3] if len(ship) >= 3 and ship[:3].isdigit() else None\n",
    "\n",
    "        if prefix and prefix_centroid is not None and prefix in prefix_centroid.index:\n",
    "            row['latitude'] = prefix_centroid.at[prefix,'latitude']\n",
    "            row['longitude'] = prefix_centroid.at[prefix,'longitude']\n",
    "            row['_imputed_by'] = f'prefix:{prefix}'\n",
    "            return row\n",
    "\n",
    "        if 'state_id' in row and pd.notna(row.get('state_id')) and state_centroid is not None:\n",
    "            st = row['state_id']\n",
    "            if st in state_centroid.index:\n",
    "                row['latitude'] = state_centroid.at[st,'latitude']\n",
    "                row['longitude'] = state_centroid.at[st,'longitude']\n",
    "                row['_imputed_by'] = f'state:{st}'\n",
    "                return row\n",
    "\n",
    "        if global_mean is not None:\n",
    "            row['latitude'] = global_mean['latitude']\n",
    "            row['longitude'] = global_mean['longitude']\n",
    "            row['_imputed_by'] = 'global_mean'\n",
    "        return row\n",
    "\n",
    "    # Apply imputation only when needed\n",
    "    if total_unmatched > 0:\n",
    "        unmatched_before = unmatched.shape[0]\n",
    "        unmatched['_imputed_by'] = np.nan\n",
    "        unmatched = unmatched.apply(impute_row, axis=1)\n",
    "        walmart_with_coords.loc[unmatched.index, ['latitude','longitude','_imputed_by']] = unmatched[['latitude','longitude','_imputed_by']]\n",
    "\n",
    "        remaining_unmatched = walmart_with_coords['latitude'].isna().sum()\n",
    "        print(f'Remaining unmatched rows after imputation: {remaining_unmatched}')\n",
    "        print('\\nImputation method counts (top examples):')\n",
    "        if '_imputed_by' in walmart_with_coords.columns:\n",
    "            print(walmart_with_coords['_imputed_by'].value_counts().head(20))\n",
    "\n",
    "        out_file = 'walmart_with_coordinates_imputed.csv'\n",
    "        walmart_with_coords.to_csv(out_file, index=False)\n",
    "        print(f'Imputed dataset saved to: {out_file}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
